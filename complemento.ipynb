{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ecc068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test Dataset Loaded: 1241 samples.\n",
      "\n",
      "\n",
      "=============== üöÄ INTERACTIVE TRADE-OFF ANALYSIS (UAR vs. Latency) ===============\n",
      "\n",
      "Select an index (from 0 to 1240) from the test set (IEMOCAP Ses. 5) to: \n",
      "1. View the Spectrogram \n",
      "2. Hear the Audio\n",
      "3. Compare the Prediction and Latency of your key models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55723dea8104f729f9b0a7266fd3766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=620, description='row_index', max=1240), Output()), _dom_classes=('widge‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# 1. IMPORTS AND INITIAL CONFIGURATION (UPDATED)\n",
    "# ====================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "from IPython.display import Audio, display\n",
    "from ipywidgets import interactive\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import timm # Added for StudentModel\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Configuration of Paths and Variables\n",
    "# ----------------------------------\n",
    "RESULTS_DIR = Path(\"results\") # Phase 1 Folder\n",
    "# If you want to use the models from results_v2, change the path to: RESULTS_DIR = Path(\"results_v2\")\n",
    "\n",
    "MODELS = {\n",
    "    # We will use the Phase 1 winner\n",
    "    \"ü•á Winning Student (RepVGG KD)\": \"best_distilled_RepVGG.pth\",\n",
    "    \"üöÄ Fastest Student (VanillaCNN KD)\": \"best_distilled_VanillaCNN.pth\",\n",
    "    \"üìâ Baseline Without KD (RepVGG)\": \"best_baseline_RepVGG.pth\",\n",
    "}\n",
    "\n",
    "# Test CSV File (IEMOCAP Session 5)\n",
    "TEST_CSV_PATH = Path(\"processed_combined_teacher/combined_test.csv\") \n",
    "\n",
    "# Preprocessing Parameters (Must match your training script)\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "MAX_DURATION_S = 8.0 # NOTE: If you used 3.0s in training, ADJUST HERE\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "# Emotion Mapping\n",
    "EMOTION_LABELS = {0: 'Anger', 1: 'Happy', 2: 'Sadness', 3: 'Neutral'}\n",
    "\n",
    "COLOR_MAP = {\n",
    "    'anger': '#e74c3c', # Red\n",
    "    'happy': '#2ecc71', # Green\n",
    "    'sad': '#3498db', # Blue\n",
    "    'neutral': '#7f8c8d'  # Gray\n",
    "}\n",
    "# Update keys to match the full English labels (Anger, Happy, Sadness, Neutral)\n",
    "# Assuming your CSV uses 'ang', 'hap', 'sad', 'neu'\n",
    "COLOR_MAP_KEYS = {'ang': 'anger', 'hap': 'happy', 'sad': 'sad', 'neu': 'neutral'}\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. CLASS DEFINITIONS (COPIED FROM YOUR TRAINING SCRIPT)\n",
    "# ------------------------------------------------\n",
    "\n",
    "class VanillaCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=4):\n",
    "        super().__init__()\n",
    "        if model_name == 'VanillaCNN':\n",
    "            self.backbone = VanillaCNN(num_classes)\n",
    "        else:\n",
    "            try:\n",
    "                # timm will load RepVGG, MobileOne, GhostNetV2\n",
    "                # pretrained=False because we only load the weights later\n",
    "                self.backbone = timm.create_model(model_name, pretrained=False, num_classes=num_classes, in_chans=1)\n",
    "            except:\n",
    "                self.backbone = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "            \n",
    "    def forward(self, x): \n",
    "        return self.backbone(x)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. DATA LOADING AND PREPROCESSING\n",
    "# ------------------------------------------------\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "    print(f\"‚úÖ Test Dataset Loaded: {len(df_test)} samples.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: CSV file not found at {TEST_CSV_PATH}. Adjust the path.\")\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    \"\"\"Loads audio, generates Mel-Spectrogram, and converts it to a tensor.\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Padding/Truncating\n",
    "    target_length = int(MAX_DURATION_S * SAMPLE_RATE)\n",
    "    if len(y) > target_length: y = y[:target_length]\n",
    "    else: y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
    "        \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS\n",
    "    )\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Normalization (IMPORTANT: Must match your training normalization)\n",
    "    if log_mel_spectrogram.std() > 1e-6:\n",
    "        log_mel_spectrogram = (log_mel_spectrogram - log_mel_spectrogram.mean()) / log_mel_spectrogram.std()\n",
    "    \n",
    "    # PyTorch expects (B, C, H, W) -> (1, 1, N_MELS, T)\n",
    "    tensor = torch.tensor(log_mel_spectrogram).float().unsqueeze(0).unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "def load_and_evaluate_model(model_name, input_tensor):\n",
    "    \"\"\"Loads a .pth model and performs inference.\"\"\"\n",
    "    model_path = RESULTS_DIR / MODELS[model_name]\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        return f\"‚ùå Model not found: {model_path}\", None\n",
    "    \n",
    "    # Select the correct base architecture name for the StudentModel Factory\n",
    "    if \"VanillaCNN\" in model_name:\n",
    "        arch_name = 'VanillaCNN'\n",
    "    elif \"RepVGG\" in model_name:\n",
    "        arch_name = 'repvgg_a0'\n",
    "    else:\n",
    "        return \"‚ùå Unknown architecture.\", None\n",
    "    \n",
    "    # Initialize the model using your StudentModel Factory\n",
    "    model = StudentModel(arch_name, num_classes=4) \n",
    "\n",
    "    # Load weights\n",
    "    try:\n",
    "        # Load state_dict to CPU (map_location='cpu')\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error loading weights: {e}\", None\n",
    "\n",
    "    # Inference and Latency Measurement (Crucial for the Trade-off)\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    latency_ms = (end_time - start_time) * 1000\n",
    "    \n",
    "    # Get probabilities and prediction\n",
    "    probabilities = F.softmax(output, dim=1).squeeze().tolist()\n",
    "    pred_index = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    # Format the result\n",
    "    results = {\n",
    "        \"prediction\": EMOTION_LABELS.get(pred_index, \"N/A\"),\n",
    "        \"latency\": f\"{latency_ms:.2f} ms\",\n",
    "        \"probabilities\": {EMOTION_LABELS[i]: p * 100 for i, p in enumerate(probabilities)}\n",
    "    }\n",
    "    return None, results\n",
    "\n",
    "def visualize_and_predict(row_index):\n",
    "    \"\"\"Main function connected to the interactive widget.\"\"\"\n",
    "    if not df_test.empty:\n",
    "        sample = df_test.iloc[row_index]\n",
    "        file_path = sample['wav_path']\n",
    "        true_emotion_code = sample['emotion'].lower()\n",
    "        true_emotion_label = EMOTION_LABELS.get(EMOTION_MAP_REVERSE.get(true_emotion_code, 3), 'N/A')\n",
    "        \n",
    "        # 1. Preprocessing and Audio\n",
    "        try:\n",
    "            input_tensor = preprocess_audio(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Preprocessing/Load Error: {e}\")\n",
    "            return\n",
    "            \n",
    "        # 2. Spectrogram Visualization\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        log_mel_spectrogram = input_tensor.squeeze().numpy()\n",
    "        \n",
    "        # üñºÔ∏è CORRECTION: Capture the image object ('img')\n",
    "        img = librosa.display.specshow(\n",
    "            log_mel_spectrogram, \n",
    "            sr=SAMPLE_RATE, \n",
    "            x_axis='time', \n",
    "            y_axis='mel', \n",
    "            ax=ax, \n",
    "            hop_length=HOP_LENGTH\n",
    "        )\n",
    "        \n",
    "        # Get color based on true emotion code\n",
    "        title_color = COLOR_MAP.get(COLOR_MAP_KEYS.get(true_emotion_code, 'black'), 'black')\n",
    "        \n",
    "        ax.set_title(f\"Spectrogram - TRUE Emotion: {true_emotion_label.upper()}\", \n",
    "                     color=title_color, \n",
    "                     fontsize=16, \n",
    "                     fontweight='bold')\n",
    "        \n",
    "        # Pass the 'img' object to the colorbar\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB') \n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 3. Play Audio\n",
    "        print(\"\\nüîä Audio (Truncated to 8 seconds):\")\n",
    "        display(Audio(file_path, rate=SAMPLE_RATE))\n",
    "        \n",
    "        # 4. Inferences and Comparison\n",
    "        print(\"\\n--- üß† Classification Results ---\")\n",
    "        \n",
    "        model_results = {}\n",
    "        for model_name in MODELS:\n",
    "            error, result = load_and_evaluate_model(model_name, input_tensor)\n",
    "            model_results[model_name] = {\"error\": error, \"result\": result}\n",
    "            \n",
    "        # 5. Tabulation of Results\n",
    "        comparison_data = []\n",
    "        \n",
    "        for model_name, data in model_results.items():\n",
    "            if data['result']:\n",
    "                pred_label_full = data['result']['prediction']\n",
    "                latency = data['result']['latency']\n",
    "                # Check if the predicted label starts with the true emotion (e.g., 'Anger' vs 'Anger (Enojo)')\n",
    "                status = \"‚úÖ Correct\" if pred_label_full.lower().startswith(true_emotion_label.lower()) else \"‚ùå Incorrect\"\n",
    "                \n",
    "                comparison_data.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prediction\": pred_label_full,\n",
    "                    \"Latency (GPU)\": latency,\n",
    "                    \"Status\": status\n",
    "                })\n",
    "            elif data['error']:\n",
    "                 comparison_data.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prediction\": data['error'],\n",
    "                    \"Latency (GPU)\": \"N/A\",\n",
    "                    \"Status\": \"ERROR\"\n",
    "                })\n",
    "\n",
    "        df_comparison = pd.DataFrame(comparison_data)\n",
    "        display(df_comparison)\n",
    "        \n",
    "        # 6. Probability Plot of the Winning Model\n",
    "        print(f\"\\nüìà Probability Distribution: {list(MODELS.keys())[0]}\")\n",
    "        \n",
    "        winner_probs_data = model_results[list(MODELS.keys())[0]]\n",
    "        \n",
    "        if winner_probs_data['result']:\n",
    "            winner_probs = winner_probs_data['result']['probabilities']\n",
    "            emotions = list(winner_probs.keys())\n",
    "            probabilities = list(winner_probs.values())\n",
    "            \n",
    "            plt.figure(figsize=(8, 4))\n",
    "            # Get colors for the bar chart\n",
    "            colors = [COLOR_MAP.get(e.lower().split()[0], 'gray') for e in emotions]\n",
    "            \n",
    "            bars = plt.bar(emotions, probabilities, color=colors)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{bar.get_height():.1f}%', ha='center', fontsize=10)\n",
    "                \n",
    "            plt.title(f\"Probabilities (RepVGG Distilled)\")\n",
    "            plt.ylabel(\"Probability (%)\")\n",
    "            plt.ylim(0, 100)\n",
    "            plt.axhline(y=25, color='gray', linestyle='--') # Random chance line (1/4)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "             print(\"Could not generate probability plot.\")\n",
    "    else:\n",
    "        print(\"The test DataFrame is empty.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. INTERACTIVE INTERFACE\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Create the widget (selector)\n",
    "sample_slider = interactive(\n",
    "    visualize_and_predict,\n",
    "    row_index=(0, len(df_test) - 1, 1), \n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "print(\"\\n\\n=============== üöÄ INTERACTIVE TRADE-OFF ANALYSIS (UAR vs. Latency) ===============\\n\")\n",
    "print(f\"Select an index (from 0 to {len(df_test)-1}) from the test set (IEMOCAP Ses. 5) to: \\n1. View the Spectrogram \\n2. Hear the Audio\\n3. Compare the Prediction and Latency of your key models.\")\n",
    "\n",
    "# Display the widget\n",
    "display(sample_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832b054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Edge Research)",
   "language": "python",
   "name": "audio_edge_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
